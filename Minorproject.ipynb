{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3cd6d99-3e63-4dd9-8881-8412153fe803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#for defining convolutional layer, pooling layers, fully connected layer,etc\n",
    "import torch.nn as nn \n",
    "#for implementing optimizing algorithm like adam\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "#for image preprocessing and agumentation\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.models as models\n",
    "import torch.fft as fft\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ff74d9a-b2fd-47b2-a955-2e8c3dfc6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e6c79a-1512-408e-83b5-2eb10805c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b66dc92-ad09-46cb-97e3-b357f8535ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pneumoniaDataset(Dataset):\n",
    "    def __init__(self, image_path, device):\n",
    "        self.image_path = image_path\n",
    "        self.device = device\n",
    "        self.data = []\n",
    "        self.transform = v2.Compose([\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Resize((227,227)),\n",
    "            v2.Normalize(mean=[0.5,], std=[0.5,]),\n",
    "            v2.Grayscale(num_output_channels=3)\n",
    "        ])\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        for idx, label in enumerate(os.listdir(os.path.join(self.image_path))):\n",
    "            print(os.path.join(self.image_path, label))\n",
    "            for img_file in tqdm(os.listdir(os.path.join(self.image_path, label))):\n",
    "                img = cv2.imread(os.path.join(self.image_path, label, img_file), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                img = self.transform(img)\n",
    "\n",
    "                idx = torch.tensor([idx])\n",
    "                self.data.append((img.to(self.device), idx.to(self.device)))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img,label= self.data[idx]\n",
    "        label=label.squeeze()\n",
    "        return img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b27e36e4-cfa0-4a94-b691-629af4a2a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since i was struglling with automatically appearing of .DS_store in my folder\n",
    "# which lead to unwanted classifying as class and  labeling it as 0 \n",
    "# Remove .DS_Store files from the folder and subfolders\n",
    "for root, dirs, files in os.walk('data'):\n",
    "    if '.DS_Store' in files:\n",
    "        os.remove(os.path.join(root, '.DS_Store'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42e952b-70b3-412c-906a-bf5eb243f3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_set/bacterial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2700/2700 [00:10<00:00, 257.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_set/normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2943/2943 [00:24<00:00, 118.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_set/viral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1491/1491 [00:07<00:00, 196.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dataset\n",
    "train_path=os.path.join('data/train_set')\n",
    "# validation_path=os.path.join('data/val_set')\n",
    "# test_path=os.path.join('data/test_set')\n",
    "train_dataset = pneumoniaDataset(image_path=train_path, device=device)\n",
    "# validation_dataset = pneumoniaDataset(image_path=validation_path, device=device)\n",
    "# test_dataset = pneumoniaDataset(image_path=test_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f6b302d-38c9-4b48-bfb1-1f06532b5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_dataset), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099eba50-6812-443c-9a7d-158d802e0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloaders\n",
    "batch_size = 24\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "# validation_dataloader=DataLoader(validation_dataset,batch_size=batch_size,shuffle=False)\n",
    "# test_dataloader=DataLoader(test_dataset,batch_size=16,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66de5850-3dd2-44b7-9ac2-da6d90717ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(validation_dataset))\n",
    "# image, label = train_dataset[6000] \n",
    "# print(image.shape)         \n",
    "# print(label)  \n",
    "# print(label.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e51d733f-5edf-4377-a4b7-a1443dbb78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the model\n",
    "# class AlexNet(nn.Module):\n",
    "#     def __init__(self,input_channels,number_of_classes):\n",
    "#         super(AlexNet, self).__init__() \n",
    "#         # Convolutional layers\n",
    "#         self.conv1 = nn.Conv2d(input_channels, 96, kernel_size=11, stride=4, padding=2)\n",
    "#         self.conv2 = nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2)\n",
    "#         self.conv3 = nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv5 = nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "#         # Fully connected layers\n",
    "#         self.fc1 = nn.Linear(9216, 4069)\n",
    "#         self.fc2 = nn.Linear(4069, 4069)\n",
    "#         self.fc3 = nn.Linear(4069, number_of_classes)\n",
    "\n",
    "#         # Other\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "#         self.norm = nn.LocalResponseNorm(size=5, k=2)\n",
    "#         self.droput = nn.Dropout(0.5)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.maxpool(self.norm(self.relu(self.conv1(x))))  # (B, 96, 27, 27)\n",
    "#         x = self.maxpool(self.norm(self.relu(self.conv2(x))))  # (B, 256, 13, 13)\n",
    "#         x = self.relu(self.conv3(x))                           # (B, 384, 13, 13)\n",
    "#         x = self.relu(self.conv4(x))                           # (B, 384, 13, 13)\n",
    "#         x = self.maxpool(self.relu(self.conv5(x)))             # (B, 256, 6, 6)\n",
    "#         x = self.flatten(x)                                    # (B, 9216)\n",
    "#         x = self.droput(self.relu(self.fc1(x)))                # (B, 4096)\n",
    "#         x = self.droput(self.relu(self.fc2(x)))                # (B, 4096)\n",
    "#         x = self.logsoftmax(self.fc3(x))                                       # (B, num_classes)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9329e0-93b3-4278-a418-da2790e5af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model=AlexNet(3,3)\n",
    "# model_cont = AlexNet(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39d8256d-fbef-429a-9775-ab5a95e16839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_cont.load_state_dict(torch.load('alexNetModel.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c293fb1a-54b7-4ff9-b4ed-68a39ea48f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(weights=None)\n",
    "model.classifier[6] = nn.Linear(in_features=4096, out_features=3, bias=True)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56c39525-1b48-4bc0-9d15-8116d2eaab05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46972a1a-cfaa-4979-a1ff-8882816f9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_epochs=10\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 0.000001\n",
    "\n",
    "#loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "# optimizer=optim.Adam(model.parameters(),learning_rate)\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a64b5c27-578a-4f69-bbbe-17939f8232ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, tensor([2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_ip = torch.randn(1,3,227,227)\n",
    "op = model(dummy_ip)\n",
    "_, op1 = torch.max(op, 1)\n",
    "op1.item(), op1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdeb8546-9979-42ff-964f-957934cc5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, optimizer, loss_fn, epochs):\n",
    "    best_acc = 0.0\n",
    "    acc_list = []\n",
    "    loss_list = []\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        total_entries = 0\n",
    "        print(f'Epoch: [{epoch+1}/{epochs}]')\n",
    "        for images, labels in tqdm(train_dl):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_entries += labels.size(0)\n",
    "            \n",
    "        epoch_loss = running_loss / total_entries\n",
    "        epoch_acc = running_corrects / total_entries\n",
    "        acc_list.append(epoch_acc)\n",
    "        loss_list.append(epoch_loss)\n",
    "        print(f\"Epoch Loss: {epoch_loss:.4f}, Epoch Accuracy: {epoch_acc:.4f}\")\n",
    "    print('Training Complete.')\n",
    "    return acc_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b60b82c5-1385-4a6a-bf83-dc6f2b61fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 298/298 [03:39<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 0.4648, Epoch Accuracy: 0.7998\n",
      "Epoch: [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▊                                     | 34/298 [00:25<03:16,  1.35it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m acc_list, loss_list \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dl, optimizer, loss_fn, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/mySpace/RohanSpace/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mySpace/RohanSpace/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mySpace/RohanSpace/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_list, loss_list = train(model, train_dataloader, optimizer, criterion, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04f2da-ca1c-49c8-9e23-2829cdd65523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_step = len(train_dataloader)\n",
    "\n",
    "# # model.to(device)\n",
    "# model_cont.to(device)\n",
    "\n",
    "# for epoch in range(number_of_epochs):\n",
    "#     # model.train()\n",
    "#     model_cont.train()\n",
    "#     for images, labels in tqdm(train_dataloader):  \n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         labels= labels.long()\n",
    "\n",
    "#         # Forward pass\n",
    "#         # outputs = model(images)\n",
    "#         outputs = model_cont(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         # Backward and optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     # model.eval()\n",
    "#     model_cont.eval()\n",
    "#     val_loss = 0.0\n",
    "#     val_correct = 0\n",
    "#     val_total = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for images,labels in validation_dataloader:\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.to(device)\n",
    "#             labels= labels.long()\n",
    "            \n",
    "#             # outputs = model(images)\n",
    "#             outputs = model_cont(images)\n",
    "#             loss = criterion(outputs,labels)\n",
    "#             val_loss += loss.item()\n",
    "\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             val_total +=labels.size(0)\n",
    "#             val_correct += (predicted ==labels).sum().item()\n",
    "\n",
    "#     # Calculate validation metrics\n",
    "#     avg_val_loss = val_loss / len(validation_dataloader)\n",
    "#     val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "#     print(f'Epoch [{epoch+1}/{number_of_epochs}], '\n",
    "#           f'Train Loss: {loss.item():.4f}, '\n",
    "#           f'Val Loss: {avg_val_loss:.4f}, '\n",
    "#           f'Val Acc: {val_accuracy:.2f}%')\n",
    "\n",
    "# print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef07db8-bb4b-4278-8a2c-d230d63babe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_cont.state_dict(), './alexNetModel.pth')\n",
    "# torch.save(model.state_dict(), './alexNetModelcont.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
